[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CODA para estudios del microbioma Seminario del proyecto METACIRCLE",
    "section": "",
    "text": "Introducci√≥n üëã"
  },
  {
    "objectID": "index.html#objetivos-del-seminario",
    "href": "index.html#objetivos-del-seminario",
    "title": "CODA para estudios del microbioma Seminario del proyecto METACIRCLE",
    "section": "Objetivos del seminario üéØ",
    "text": "Objetivos del seminario üéØ\n1.- Discutiremos las diferencias entre trabajar con conteos absolutos (abundancias absolutas) y conteos normalizados (abundancias relativas).\n2.- Indicaremos los principios de CODA.\n3.- Mostraremos el tool kit de CODA de microbioma.\n4.- CODA en acci√≥n: ejemplo de an√°lisis de datos composicionales."
  },
  {
    "objectID": "t1.html#inconvenientes-de-compararar-muestras-con-abundancias-relativas",
    "href": "t1.html#inconvenientes-de-compararar-muestras-con-abundancias-relativas",
    "title": "1¬† Inconvenientes de trabajar con conteos absolutos y conteos normalizados ü§Ø",
    "section": "1.1  Inconvenientes de compararar muestras con abundancias relativas  üòµ",
    "text": "1.1  Inconvenientes de compararar muestras con abundancias relativas  üòµ\n\nSi normalizamos, de manera de que las sumas totales de las filas no importa, entonces las matrices de distancias usuales entre muestras, cambian.\n\nEjemplo\n\nset.seed(5)\nlibrary(ecodist)\nx= round( rnorm (3 ,100 ,10) )\ny= round( rnorm (3 ,100 ,10) )\nz= round( rnorm (3 ,1000 ,100) )\nX= cbind(x,y,z)\nknitr::kable(X) #Conteos absolutos\n\n\n\n\nx\ny\nz\n\n\n\n\n92\n101\n953\n\n\n114\n117\n936\n\n\n87\n94\n971\n\n\n\n\nknitr::kable(as.matrix(bcdist(X),ncol=2)) # Matriz de distancia de Bray-Curtis conteos absolutos\n\n\n\n\n1\n2\n3\n\n\n\n\n0.0000000\n0.0237786\n0.0130548\n\n\n0.0237786\n0.0000000\n0.0366537\n\n\n0.0130548\n0.0366537\n0.0000000\n\n\n\n\nX1=apply(X, 1, function (x) x/sum(x)) \nknitr::kable(X1) #Conteos normalizados\n\n\n\n\nx\n0.0802792\n0.0976864\n0.0755208\n\n\ny\n0.0881326\n0.1002571\n0.0815972\n\n\nz\n0.8315881\n0.8020566\n0.8428819\n\n\n\n\nknitr::kable(as.matrix(bcdist(X1),ncol=2)) # Matriz de distancia de Bray-Curtis conteos normalizados\n\n\n\n\n\nx\ny\nz\n\n\n\n\nx\n0.0000000\n0.0315212\n0.8142965\n\n\ny\n0.0315212\n0.0000000\n0.8033966\n\n\nz\n0.8142965\n0.8033966\n0.0000000\n\n\n\n\n\n\n\nAlgunas soluciones:\n\nSubsampling, pero se pierde precisi√≥n.\nUsar solo proporciones, pero se a√±aden correlaciones espurias \n\n\n\n\nCorrelaci√≥n espuria (Pearson 1896).\n\nDos o m√°s OTUs estar√°n correlacionados simplemente porque los datos han sido transformados a una suma constante.\n\n\n\n\n\nIncoherencia subcomposicional\n\n\n\n\n\n\n Si hemos normalizado, los conteos de los microorganismos no son variables independientes ya que est√°n ligados por el valor de la suma."
  },
  {
    "objectID": "t1.html#soluci√≥n",
    "href": "t1.html#soluci√≥n",
    "title": "1¬† Inconvenientes de trabajar con conteos absolutos y conteos normalizados ü§Ø",
    "section": "1.2 Soluci√≥n",
    "text": "1.2 Soluci√≥n\n\n\n Utilizamos otra forma de ‚Äúnormalizar‚Äù que preserva la composici√≥n de cada muestra y nos permite compararlas:\n\nCODA= Compositional Data Analysis"
  },
  {
    "objectID": "t2.html#metodolog√≠a",
    "href": "t2.html#metodolog√≠a",
    "title": "2¬† Principios b√°sicos del CODA",
    "section": "2.1  Metodolog√≠a ",
    "text": "2.1  Metodolog√≠a"
  },
  {
    "objectID": "t3.html",
    "href": "t3.html",
    "title": "3¬† Reemplazos composicionales del tool kit tradicional üëÄ",
    "section": "",
    "text": "Distancia de Aitchison\n\nLa distancia de Aitchison no es m√°s que la distancia euclidiana entre muestras despu√©s de transformaci√≥n clr.\n\n\n\n\n\nCorrelaciones de datos composicionales\nExisten varias t√©cnicas para analizar la correlaci√≥n de los datos del microbioma que suelen ser matrices ‚Äúsparce‚Äù. Uno de ellos es r-sparc."
  },
  {
    "objectID": "coda_ejemplo1.html",
    "href": "coda_ejemplo1.html",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "",
    "text": "5 Tratamiento de los ceros"
  },
  {
    "objectID": "coda_ejemplo1.html#carga-de-librer√≠as",
    "href": "coda_ejemplo1.html#carga-de-librer√≠as",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "4.1 Carga de librer√≠as",
    "text": "4.1 Carga de librer√≠as\n\nset.seed(1)\nlibrary(data.table)\nlibrary(compositions) \nlibrary(zCompositions) \nlibrary(ALDEx2) \nlibrary(kableExtra)\nlibrary(ggplot2)\nlibrary(easyCODA)\nlibrary(RColorBrewer)\nlibrary(robCompositions)\nlibrary(dendextend)\nlibrary(coda4microbiome)\nlibrary(propr)\nlibrary(ppclust)\nlibrary(factoextra)\nlibrary(cluster)\nlibrary(fclust)\nlibrary(nnet)\nlibrary(corrplot)\nsource(\"funcionsCODACesc.R\")"
  },
  {
    "objectID": "coda_ejemplo1.html#carga-y-limpieza-de-los-datos",
    "href": "coda_ejemplo1.html#carga-y-limpieza-de-los-datos",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "4.2 Carga y limpieza de los datos",
    "text": "4.2 Carga y limpieza de los datos\n\nDF.0=read.table(\"count_table_otus.tsv\",header=TRUE,sep=\"\\t\")\nrownames(DF.0)=DF.0[,1]\nDF.0=DF.0[,-1]\n# Eliminando los _\nrownames(DF.0)=gsub(\"_\",\".\", rownames(DF.0))\ncolnames(DF.0)=gsub(\"_\",\".\", colnames(DF.0))\n\n# Las filas deben ser muestras y las columnas taxa \nDF.0=t(DF.0)\ndim(DF.0)\n\n[1] 218 280\n\n# [1] 218 280\n# Eliminamos las filas y columnas con 0\nDF.0=DF.0[apply(DF.0, 1, sum)>0,apply(DF.0, 2, sum)>0]\nmostres=rownames(DF.0)\nbitxos=colnames(DF.0)\ncolnames(DF.0)=1:dim(DF.0)[2]\nGrups=as.factor(substr(mostres,1,1)) \ncolors=c(\"green\",\"blue\",\"brown\")[Grups]"
  },
  {
    "objectID": "coda_ejemplo1.html#g√©neros-que-aparecen-√∫nicamente-en-un-tipo-de-muestra",
    "href": "coda_ejemplo1.html#g√©neros-que-aparecen-√∫nicamente-en-un-tipo-de-muestra",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.1 G√©neros que aparecen √∫nicamente en un tipo de muestra",
    "text": "5.1 G√©neros que aparecen √∫nicamente en un tipo de muestra\n\nSolo en Adultos\n\n\nbitxos.nomesA=bitxos[which(apply(DF.0[Grups!=\"A\",], 2, sum)==0)]\nlength(bitxos.nomesA)\n\n[1] 4\n\nbitxos.nomesA%>%\n  kbl() %>%\n  kable_styling()\n\n\n\n \n  \n    x \n  \n \n\n  \n    OTU.196 \n  \n  \n    OTU.254 \n  \n  \n    OTU.260 \n  \n  \n    OTU.270 \n  \n\n\n\n\n\n\nSolo en los Ancianos (Elderly)\n\n\nbitxos.nomesE=bitxos[which(apply(DF.0[Grups!=\"E\",], 2, sum)==0)]\nlength(bitxos.nomesE)\n\n[1] 16\n\nbitxos.nomesE%>%\n  kbl() %>%\n  kable_styling()\n\n\n\n \n  \n    x \n  \n \n\n  \n    OTU.147 \n  \n  \n    OTU.153 \n  \n  \n    OTU.165 \n  \n  \n    OTU.214 \n  \n  \n    OTU.216 \n  \n  \n    OTU.217 \n  \n  \n    OTU.234 \n  \n  \n    OTU.239 \n  \n  \n    OTU.246 \n  \n  \n    OTU.251 \n  \n  \n    OTU.253 \n  \n  \n    OTU.257 \n  \n  \n    OTU.261 \n  \n  \n    OTU.271 \n  \n  \n    OTU.273 \n  \n  \n    OTU.278 \n  \n\n\n\n\n\n\nSolo en los Infantes\n\n\nbitxos.nom√©sI=bitxos[which(apply(DF.0[Grups!=\"I\",], 2, sum)==0)]\nlength(bitxos.nom√©sI)\n\n[1] 6\n\nbitxos.nom√©sI%>%\n  kbl() %>%\n  kable_styling()\n\n\n\n \n  \n    x \n  \n \n\n  \n    OTU.119 \n  \n  \n    OTU.138 \n  \n  \n    OTU.220 \n  \n  \n    OTU.225 \n  \n  \n    OTU.277 \n  \n  \n    OTU.279 \n  \n\n\n\n\n\n\nSolo en uno\n\n\nNomes.a.un=which(apply(DF.0[Grups!=\"A\",], 2, sum)==0 | apply(DF.0[Grups!=\"E\",], 2, sum)==0 | apply(DF.0[Grups!=\"I\",], 2, sum)==0)"
  },
  {
    "objectID": "coda_ejemplo1.html#imputaci√≥n-de-ceros-con-la-previa-de-jeffreys",
    "href": "coda_ejemplo1.html#imputaci√≥n-de-ceros-con-la-previa-de-jeffreys",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.2 Imputaci√≥n de ceros con la previa de Jeffreys",
    "text": "5.2 Imputaci√≥n de ceros con la previa de Jeffreys\n\n#cmultRepl de la librer√≠a zCompositions Bayesian-Multiplicative replacement of count zeros\n# previa de Jeffreys 1/2, todos los valores tienen la misma probabilidad de ocurrir.\n\nDF.J=cmultRepl(DF.0, method=\"user\", t=matrix(1/dim(DF.0)[2],nrow=dim(DF.0)[1],ncol=dim(DF.0)[2]),s=rep(dim(DF.0)[2]/2,dim(DF.0)[1]),\n               output=\"p-counts\",suppress.print=TRUE)"
  },
  {
    "objectID": "coda_ejemplo1.html#imputaci√≥n-de-ceros-con-geometric-bayesian-multiplicative",
    "href": "coda_ejemplo1.html#imputaci√≥n-de-ceros-con-geometric-bayesian-multiplicative",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.3 Imputaci√≥n de ceros con Geometric Bayesian multiplicative",
    "text": "5.3 Imputaci√≥n de ceros con Geometric Bayesian multiplicative\n\n# Este es el m√©todo por defecto de cmultRepl \n# Hay que quitar columnas con solo una entrada diferente a 0\nUnics=which(apply(DF.0, 2, function(x){length(which(x>0))})==1)\nbitxos.unics=bitxos[Unics]\nlength(bitxos.unics)\n\n[1] 3\n\nbitxos.unics%>%\n  kbl(col.names =NULL) %>%\n  kable_styling()\n\n\n\n\n  \n    OTU.138 \n  \n  \n    OTU.220 \n  \n  \n    OTU.251 \n  \n\n\n\n\n\nDamos un vistazo a lo que nos perderemos si las quitamos: Sus frecuencias relativas dentro de sus muestras √∫nicas\n\nQu√®.ens.perdem=rep(0,length(Unics))\nfor (i in 1:length(Unics)){\n  y=attr(Unics,\"names\")[i]\n  x=which(DF.0[,y]>0)\n  Qu√®.ens.perdem[i]=DF.0[x,y]/sum(DF.0[x,])\n}\nround(Qu√®.ens.perdem,6)\n\n[1] 0.024063 0.001049 0.000288\n\n\nLa matriz con los ceros imputados ‚Ä¶\n\nDF.0U=DF.0[,-Unics]\nDF.GBM=cmultRepl(DF.0U,method=\"GBM\",output=\"p-counts\",suppress.print=TRUE)\nbitxos.nounics=bitxos[-Unics]"
  },
  {
    "objectID": "coda_ejemplo1.html#imputaci√≥n-de-ceros-con-un-m√©todo-iterativo",
    "href": "coda_ejemplo1.html#imputaci√≥n-de-ceros-con-un-m√©todo-iterativo",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.4 Imputaci√≥n de ceros con un m√©todo Iterativo",
    "text": "5.4 Imputaci√≥n de ceros con un m√©todo Iterativo\n\n# impRZilr de la librer√≠a robCompositions\n# \n# Tarda mucho en compilar\n# DF.0n=as.data.frame(DF.0)\n# DF.0n=as.data.frame(apply(DF.0n,MARGIN=2,as.numeric))\n# DF.It=impRZilr(DF.0n, eps=0.05, method = \"pls\", dl=rep(1, dim(DF.0)[2]),maxit = 10,verbose = FALSE)\n# saveRDS(DF.It, file=\"DFItnou.RData\")\n\n\nDF.It=readRDS(\"DFItnou.RData\")$x"
  },
  {
    "objectID": "coda_ejemplo1.html#qu√©-m√©todo-para-imputar-los-ceros-es-mejor",
    "href": "coda_ejemplo1.html#qu√©-m√©todo-para-imputar-los-ceros-es-mejor",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.5 ¬øQu√© m√©todo para imputar los ceros es mejor?",
    "text": "5.5 ¬øQu√© m√©todo para imputar los ceros es mejor?\n(Lubbe-Filznoser-Templ Chemolab 2021)\nComparando matrices de correlaciones de Kynclova-Hron-Filzmoser: un valor peque√±o indica que el m√©todo es mejor.\nLa funci√≥n corCoDa del paquete robCompositions que las calcula no aguanta matrices grandes (al menos en el ordenador de Cesc), por lo tanto lo ha hecho por muestreo.\n\n# Sustituci√≥n de los ceros por algo muy peque√±o\n# multRepl de la librer√≠a zCompositions\nDF.0.alt=multRepl(DF.0,dl=rep(1, ncol(DF.0)),frac=10^(-12),label=0)\nDF.0.alt.U=DF.0.alt[,-Unics]\n\n\n# X Y con las mismas dimensiones\n# m < 30 o  da NaN\nf=function(X,Y,m){\nx=sample(dim(X)[2],m)\n(1/m)^2*sum((corCoDa(X[,x])-corCoDa(Y[,x]))^2)\n}\nmean(replicate(200,f(DF.0.alt,DF.J,25)))\nmean(replicate(200,f(DF.0.alt.U,DF.GBM,25)))\nmean(replicate(200,f(DF.0.alt,DF.It,25)))\n# [1] 0.01688433 0.01664001\n# [1] 0.009403911 0.009399878\n# [1] 0.06253841 0.05720421"
  },
  {
    "objectID": "coda_ejemplo1.html#comparando-matrices-de-distancias-de-aitchison-valor-peque√±o-indica-mejor.",
    "href": "coda_ejemplo1.html#comparando-matrices-de-distancias-de-aitchison-valor-peque√±o-indica-mejor.",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.6 Comparando matrices de distancias de Aitchison: valor peque√±o indica mejor.",
    "text": "5.6 Comparando matrices de distancias de Aitchison: valor peque√±o indica mejor.\n\n(1/dim(DF.0)[1])^2*sum((aDist(DF.0.alt)-aDist(DF.J))^2)\n\n[1] 20279.85\n\n(1/dim(DF.0U)[1])^2*sum((aDist(DF.0.alt.U)-aDist(DF.GBM))^2)\n\n[1] 19972.44\n\n#(1/dim(DF.0)[1])^2*sum((aDist(DF.0.alt)-aDist(DF.It))^2)\n\n\nImputa0=c(\"J\",\"GBM\",\"It\")\nImputa0=\"GBM\"\nif (Imputa0==\"J\"){\n    DF=DF.J\n}\nif (Imputa0==\"GBM\"){\n  DF.0=DF.0U\n  DF=DF.GBM\n  bitxos=bitxos.nounics\n} \nif (Imputa0==\"It\"){\n    DF=DF.It\n}"
  },
  {
    "objectID": "coda_ejemplo1.html#si-se-quieren-filtrar-las-muestras-outliers",
    "href": "coda_ejemplo1.html#si-se-quieren-filtrar-las-muestras-outliers",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.7 Si se quieren filtrar las muestras outliers",
    "text": "5.7 Si se quieren filtrar las muestras outliers\nQuitamos muestras que contribuyen a tener mucha varianza\nUtiliz√≥ codaSeq.outlier de funcionsCODACesc.R adaptada de EasyCODA, que le da error\n\nDF.CLR=acomp(DF)\nCSOut=codaSeq.outlier(DF.CLR, plot.me=TRUE)\n\n\n\n\n\n\n\noutliers=CSOut$bad\nbones=CSOut$good\n\nLas muestras outliers son\n\nmostres[outliers]\n\n [1] \"A04T4\" \"A05T1\" \"A07T2\" \"A08T4\" \"A08T6\" \"E01T1\" \"E01T2\" \"E06T4\" \"E09T2\"\n[10] \"E10T3\" \"I01T2\" \"I01T4\" \"I02T7\" \"I05T2\" \"I07T4\" \"I07T6\" \"I07T7\" \"I09T2\"\n[19] \"I10T6\"\n\n\nSi quitamos estas muestras, tenemos que volver a controlar que no nos quede ninguna columna de 0s\n\nDF.0B=DF.0[bones,]\nconserv=which(apply(DF.0B, 2, sum)>0) \nDF.0B=DF.0B[ ,conserv]\n\n\n# si se emplea DF.It, igual conviene re-calcularlo porque depende de las muestras\n\n# Hay que quitar bichos que hayan quedado a 0 en todo\nconserv=which(apply(DF.0B, 2, sum)>0) \nDF.0B=DF.0B[ ,conserv]\nDF.0Bn=as.data.frame(DF.0B)\nDF.0Bn=as.data.frame(apply(DF.0Bn,MARGIN=2,as.numeric))\nDFB.It=impRZilr(DF.0Bn, eps=0.05, method = \"pls\", dl=rep(1, dim(DF.0B)[2]),maxit = 10,verbose = FALSE)\nsaveRDS(DFB.It, file=\"DFItBnou.RData\")\n\nCon la funci√≥n QuinesMostres indicamos si cogemos solo las muestras buenas o todas\n\n#QuinesMostres=c(\"totes\",\"bones\") \nQuinesMostres=\"bones\"\nif (QuinesMostres==\"bones\"){\n  DF.0=DF.0B\n  DF=DF[bones,conserv]\n  Grups=Grups[bones]\ncolors=colors[bones]\nmostres=mostres[bones]\n    bitxos=bitxos[conserv]\n}\nDF.CLR=acomp(DF)\nDF.prop=t(apply(DF, 1, function(x){x/sum(x)}))"
  },
  {
    "objectID": "coda_ejemplo1.html#sin-filtrar-variables",
    "href": "coda_ejemplo1.html#sin-filtrar-variables",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.8 Sin filtrar variables",
    "text": "5.8 Sin filtrar variables\nNo hace biplot porque con tanta variable no se ve nada"
  },
  {
    "objectID": "coda_ejemplo1.html#clustering-jer√°rquico",
    "href": "coda_ejemplo1.html#clustering-jer√°rquico",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.9 Clustering jer√°rquico",
    "text": "5.9 Clustering jer√°rquico\n\n# Clustering jer√°rquico con distancias euclidianas con pesos\n# Funci√≥n WARD de EasyCODA, necesita que la matriz de clr's se calcule con la misma librer√≠a\nDF.CLR.W=CLR(DF)\nhc=WARD(DF.CLR.W,weight=TRUE)\ndend=as.dendrogram(hc)\nlabels_colors(dend)=colors[hc$order]\npar(cex=0.75)\nplot(dend, main = \"\")\n\n\n\n\n\n\n\npar(cex=1)\n# No dibujamos barplot de composiciones porque el gr√°fico no es informativo\n\n\nclust1=data.frame(Orig=Grups[hc$order],\n             clust=cutree(dend, k = 3)[order.dendrogram(dend)])\ntable(clust1)%>%\n  kbl() %>%\n  kable_styling()\n\n\n\n \n  \n      \n    1 \n    2 \n    3 \n  \n \n\n  \n    A \n    51 \n    14 \n    0 \n  \n  \n    E \n    25 \n    28 \n    16 \n  \n  \n    I \n    57 \n    0 \n    8"
  },
  {
    "objectID": "coda_ejemplo1.html#aldex",
    "href": "coda_ejemplo1.html#aldex",
    "title": "4¬† CODA en acci√≥n üòé: Ejemplo 1 (A,E,I)",
    "section": "5.10 ALDEx",
    "text": "5.10 ALDEx\nALDEx2 estima la variaci√≥n por edad (A, E, I) dentro de cada muestra utilizando el m√©todo de Monte Carlo, las muestras se extraen de la distribuci√≥n Dirichlet (la beta en el caso multivariado). El muestreo a partir de esta distribuci√≥n devuelve la distribuci√≥n de probabilidad posterior de los datos observados bajo un modelo de muestreo repetido. Todas las salidas de ALDEx2 son salidas de las distribuciones posteriores, ya sean valores esperados o intervalos de confianza.\n\nDF0.Aldex=rbind(DF.0[Grups==\"A\",],DF.0[Grups==\"E\",], DF.0[Grups==\"I\",])\nDF0.t=data.frame(t(DF0.Aldex))\nconds=c(rep(\"A\", dim(DF.0[Grups==\"A\",])[1]),rep(\"E\", dim(DF.0[Grups==\"E\",])[1]), rep(\"I\", dim(DF.0[Grups==\"I\",])[1]))\n#'\nx.clr.kw=aldex.clr(DF0.t[,1:5], conds=conds[1:5], mc.samples=10, verbose=FALSE)\nmc.instances <- numMCInstances(x.clr.kw)\nmc.all <- getMonteCarloInstances(x.clr.kw)\n\n\nDF0.Aldex=rbind(DF.0[Grups==\"A\",],DF.0[Grups==\"E\",], DF.0[Grups==\"I\",])\nDF0.t=data.frame(t(DF0.Aldex))\nconds=c(rep(\"A\", dim(DF.0[Grups==\"A\",])[1]),rep(\"E\", dim(DF.0[Grups==\"E\",])[1]), rep(\"I\", dim(DF.0[Grups==\"I\",])[1]))\n#\nx.clr.kw=aldex.clr(DF0.t, conds=conds, mc.samples=1000, verbose=FALSE)\nx.kw=aldex.kw(x.clr.kw, verbose=FALSE)\n# valores esperados del test Kruskal-Wallis y un glm sobre los datos\nmm=model.matrix(~conds,data.frame(conds))\nx.clr.glm=aldex.clr(DF0.t, conds=mm, mc.samples=1000, verbose=FALSE)\nx.glm=aldex.glm(x.clr.glm, mm)\n#\nx.tot=cbind(bitxos,x.kw,x.glm) \nsaveRDS(x.tot, file=\"xtotTotal.RData\")\n\n\nx.tot=readRDS(\"xtotTotal.RData\")\nx.tot$bitxos=paste0(\"OTU.\",c(paste(\"00\",1:9),paste(\"0\",10:99),100:276))\n\n\nx.tot=readRDS(\"xtotTotal.RData\")\n\n\nhead(x.tot)%>%\n  kbl() %>%\n  kable_styling()\n\n\n\n \n  \n    bitxos \n    kw.ep \n    kw.eBH \n    glm.ep \n    glm.eBH \n    Intercept::Est \n    Intercept::SE \n    Intercept::t.val \n    Intercept::pval \n    condsE:Est \n    condsE:SE \n    condsE:t.val \n    condsE:pval \n    condsI:Est \n    condsI:SE \n    condsI:t.val \n    condsI:pval \n    Intercept::pval.holm \n    condsE:pval.holm \n    condsI:pval.holm \n  \n \n\n  \n    OTU.00 1 \n    0.0801547 \n    0.1570136 \n    0.0303225 \n    0.0797589 \n    11.554637 \n    0.1854587 \n    62.30798 \n    0 \n    0.3413483 \n    0.2584491 \n    1.3206900 \n    0.1903230 \n    0.6980545 \n    0.2622782 \n    2.6615681 \n    0.0087659 \n    0 \n    1.0000000 \n    0.9977548 \n  \n  \n    OTU.00 2 \n    0.0206440 \n    0.0579031 \n    0.8077564 \n    0.8585892 \n    10.371632 \n    0.3250578 \n    31.95125 \n    0 \n    -0.2775871 \n    0.4529898 \n    -0.6145031 \n    0.5414810 \n    -0.1943723 \n    0.4597011 \n    -0.4203944 \n    0.6775020 \n    0 \n    1.0000000 \n    1.0000000 \n  \n  \n    OTU.00 3 \n    0.0000000 \n    0.0000001 \n    0.0000000 \n    0.0000001 \n    11.002260 \n    0.2578001 \n    42.77776 \n    0 \n    -1.3076398 \n    0.3592617 \n    -3.6427641 \n    0.0003698 \n    1.0649519 \n    0.3645844 \n    2.9277117 \n    0.0042881 \n    0 \n    0.0972514 \n    0.8239804 \n  \n  \n    OTU.00 4 \n    0.0005343 \n    0.0031584 \n    0.0136801 \n    0.0424850 \n    8.736565 \n    0.5371141 \n    16.30443 \n    0 \n    -2.1272875 \n    0.7485045 \n    -2.8451954 \n    0.0060917 \n    -0.4423784 \n    0.7595941 \n    -0.5828832 \n    0.5672890 \n    0 \n    0.8664487 \n    1.0000000 \n  \n  \n    OTU.00 5 \n    0.0017423 \n    0.0078298 \n    0.0006925 \n    0.0041580 \n    12.369761 \n    0.1919890 \n    64.43325 \n    0 \n    -0.8996720 \n    0.2675496 \n    -3.3628596 \n    0.0009802 \n    -0.0119042 \n    0.2715135 \n    -0.0438439 \n    0.9315986 \n    0 \n    0.2511886 \n    1.0000000 \n  \n  \n    OTU.00 6 \n    0.0008415 \n    0.0044561 \n    0.0350900 \n    0.0835593 \n    9.693963 \n    0.2458796 \n    39.53140 \n    0 \n    0.0115472 \n    0.3426497 \n    0.0338475 \n    0.9425424 \n    0.8127551 \n    0.3477263 \n    2.3506040 \n    0.0246736 \n    0 \n    1.0000000 \n    1.0000000 \n  \n\n\n\n\n\nAqu√≠ podemos basarnos en kw.eBH, glm.eBH, model.condsE, Pr(>|t|).BH, model.condsI Pr(>|t|).BH\n\nsignif.p1=which(x.tot$kw.eBH < 0.01)\nsignif.g1=which(x.tot$glm.eBH < 0.01)\nsignif.p1=intersect(signif.p1,signif.g1)\n\nlength(signif.p1)\n\n[1] 40\n\nx.tot.sign=x.tot[signif.p1,c(3,5,19,20)]\nnames(x.tot.sign)=c(\"p-val KW corregit\", \"p-val glm corregit\", \"p-val E vs A corregit\", \"p-val I vs A corregit\")\nrownames(x.tot.sign)=bitxos[signif.p1]\n\nx.tot.sign%>%\n  kbl() %>%\n  kable_styling()\n\n\n\n \n  \n      \n    p-val KW corregit \n    p-val glm corregit \n    p-val E vs A corregit \n    p-val I vs A corregit \n  \n \n\n  \n    OTU.003 \n    0.0000001 \n    0.0000001 \n    0.0972514 \n    0.8239804 \n  \n  \n    OTU.005 \n    0.0078298 \n    0.0041580 \n    0.2511886 \n    1.0000000 \n  \n  \n    OTU.008 \n    0.0000070 \n    0.0000016 \n    1.0000000 \n    0.0000085 \n  \n  \n    OTU.011 \n    0.0010125 \n    0.0059162 \n    1.0000000 \n    0.0787355 \n  \n  \n    OTU.013 \n    0.0000433 \n    0.0000009 \n    0.2828991 \n    0.5834326 \n  \n  \n    OTU.016 \n    0.0038849 \n    0.0006962 \n    0.0327502 \n    1.0000000 \n  \n  \n    OTU.020 \n    0.0097656 \n    0.0033890 \n    1.0000000 \n    0.0918489 \n  \n  \n    OTU.022 \n    0.0000326 \n    0.0000097 \n    1.0000000 \n    0.0358061 \n  \n  \n    OTU.025 \n    0.0002163 \n    0.0001919 \n    1.0000000 \n    0.0091624 \n  \n  \n    OTU.030 \n    0.0000002 \n    0.0000000 \n    0.0002360 \n    0.0000002 \n  \n  \n    OTU.034 \n    0.0000000 \n    0.0000000 \n    1.0000000 \n    0.0000011 \n  \n  \n    OTU.038 \n    0.0001000 \n    0.0006898 \n    1.0000000 \n    0.0438187 \n  \n  \n    OTU.044 \n    0.0000015 \n    0.0000002 \n    1.0000000 \n    0.0000073 \n  \n  \n    OTU.046 \n    0.0011419 \n    0.0006191 \n    0.5639068 \n    0.0063995 \n  \n  \n    OTU.047 \n    0.0001250 \n    0.0001823 \n    0.2585800 \n    0.9991464 \n  \n  \n    OTU.049 \n    0.0053303 \n    0.0072328 \n    0.1026868 \n    0.9789205 \n  \n  \n    OTU.050 \n    0.0000264 \n    0.0002277 \n    0.3148470 \n    1.0000000 \n  \n  \n    OTU.052 \n    0.0001237 \n    0.0075423 \n    0.9952454 \n    1.0000000 \n  \n  \n    OTU.054 \n    0.0013229 \n    0.0097693 \n    1.0000000 \n    0.7449599 \n  \n  \n    OTU.057 \n    0.0000489 \n    0.0000655 \n    1.0000000 \n    0.1825672 \n  \n  \n    OTU.059 \n    0.0000000 \n    0.0000000 \n    1.0000000 \n    0.0000004 \n  \n  \n    OTU.060 \n    0.0002872 \n    0.0042465 \n    0.6414395 \n    1.0000000 \n  \n  \n    OTU.063 \n    0.0004161 \n    0.0014406 \n    0.4197127 \n    1.0000000 \n  \n  \n    OTU.064 \n    0.0000174 \n    0.0001876 \n    1.0000000 \n    0.0845730 \n  \n  \n    OTU.066 \n    0.0000025 \n    0.0000036 \n    0.0061348 \n    0.0000254 \n  \n  \n    OTU.067 \n    0.0003092 \n    0.0026454 \n    0.7734519 \n    0.0414771 \n  \n  \n    OTU.075 \n    0.0091920 \n    0.0052941 \n    0.1359825 \n    1.0000000 \n  \n  \n    OTU.077 \n    0.0000837 \n    0.0003245 \n    0.9095772 \n    0.9990152 \n  \n  \n    OTU.078 \n    0.0001277 \n    0.0005558 \n    0.7500225 \n    1.0000000 \n  \n  \n    OTU.086 \n    0.0005582 \n    0.0022955 \n    0.1265078 \n    1.0000000 \n  \n  \n    OTU.088 \n    0.0000000 \n    0.0000000 \n    1.0000000 \n    0.0000000 \n  \n  \n    OTU.091 \n    0.0000012 \n    0.0000026 \n    0.6333928 \n    0.4631056 \n  \n  \n    OTU.096 \n    0.0007613 \n    0.0024963 \n    0.7773785 \n    0.9987909 \n  \n  \n    OTU.100 \n    0.0087198 \n    0.0049639 \n    0.4523354 \n    1.0000000 \n  \n  \n    OTU.101 \n    0.0000000 \n    0.0000000 \n    1.0000000 \n    0.0000138 \n  \n  \n    OTU.102 \n    0.0000000 \n    0.0000053 \n    0.9922000 \n    0.0525332 \n  \n  \n    OTU.111 \n    0.0004223 \n    0.0016563 \n    0.3737696 \n    0.0432119 \n  \n  \n    OTU.113 \n    0.0021340 \n    0.0040426 \n    0.1122496 \n    1.0000000 \n  \n  \n    OTU.118 \n    0.0000004 \n    0.0000050 \n    0.8946424 \n    0.0804560 \n  \n  \n    OTU.154 \n    0.0010999 \n    0.0060971 \n    0.1554282 \n    0.9981464 \n  \n\n\n\n\nprova=unlist(sapply(rownames(x.tot.sign),FUN=function(x) which(x==x.tot$bitxos)))\nnames(prova)=NULL\n\nSi nos restringimos a estos bichos:\n\nDF.s=DF[,prova]\nDF.CLR=acomp(DF.s) \n\n\npcx=princomp(DF.CLR,cor=TRUE) \n\n\ncoloredBiplot(pcx, cex=0.5, col=\"red\",  arrow.len=0, scale=1,var.axes=TRUE,\n    xlab=paste(\"PC1\", round(pcx$sdev[1]^2 / sum(pcx$sdev^2),3), sep=\": \"),\n    ylab=paste(\"PC2\", round(pcx$sdev[2]^2 / sum(pcx$sdev^2),3), sep=\": \"),\n    xlabs.col=colors, main=\"Form biplot\")\n\n\n\n\n\n\n\n\n\nDF.CLR.W.s=CLR(DF.s)\nhc2=WARD(DF.CLR.W.s,weight=TRUE)\ndend.2=as.dendrogram(hc2)\nlabels_colors(dend.2)=colors[hc2$order]\nDFOr=DF.s[hc2$order,]\n#Reordemanos las muestras para dibujar los barplot en el mismo orden\nDFOr.CLR=acomp(DFOr)\nd.names=colnames(DF.s)[order(apply(DF.s, 2, sum), decreasing=T) ]\nnb.cols=dim(DF.s)[2]\ncolors.OTU=colorRampPalette(brewer.pal(length(d.names),\"Spectral\"))(nb.cols)\n#Dibujo\nlayout(matrix(c(1,3,2,3),2,2, byrow=T), widths=c(6,2), height=c(4,4))\npar(mar=c(2,1,1,1)+0.1,cex=0.75)\nplot(dend.2, main = \"\")\nbarplot(DFOr.CLR, legend.text=F, col=colors.OTU, axisnames=F, border=NA, xpd=T,)\npar(mar=c(0,1,1,1)+0.1,cex=1)\nplot(1,2, pch = 1, lty = 1, ylim=c(-20,20), type = \"n\", axes = FALSE, ann = FALSE)\nlegend(x=\"center\", legend=d.names, col=colors.OTU, lwd=5, cex=.6, border=NULL)"
  }
]